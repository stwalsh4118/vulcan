# 4-7 Firecracker Prometheus Metrics

[Back to task list](./tasks.md)

## Description

Register and instrument Firecracker-specific Prometheus metrics to provide observability into microVM operations. Metrics cover VM boot time, active VM count, vsock communication latency, and VM cleanup duration. These are instrumented within the Firecracker backend's Execute and Cleanup methods.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2026-02-19 08:35:03 | Created | N/A | Proposed | Task file created | AI_Agent |
| 2026-02-19 10:40:49 | Status Change | Proposed | InProgress | Started implementation | AI_Agent |
| 2026-02-19 10:45:35 | Status Change | InProgress | Review | Implementation complete, internal AI review passed (2 rounds) | AI_Agent |
| 2026-02-20 04:40:03 | Status Change | Review | Done | Task completed and verified | AI_Agent |

## Requirements

1. **Metrics** (`internal/backend/firecracker/metrics.go`):
   - `vulcan_firecracker_vm_boot_seconds` — histogram of VM boot duration (from Machine.Start to guest agent ready).
   - `vulcan_firecracker_active_vms` — gauge of currently running microVMs.
   - `vulcan_firecracker_vsock_latency_seconds` — histogram of vsock round-trip time (send request to first response byte).
   - `vulcan_firecracker_vm_cleanup_seconds` — histogram of cleanup duration (stop VM + teardown networking).
   - `vulcan_firecracker_workloads_total` — counter of workloads processed, labeled by `{runtime, status}` (completed/failed/killed).

2. **Instrumentation points** in the backend Execute flow:
   - Record boot time: start timer at VM start, stop when vsock connection established.
   - Increment active VMs gauge on boot, decrement on cleanup.
   - Record vsock latency: start timer at request send, stop at first log line or result received.
   - Record cleanup duration: start timer at stop VM, stop when teardown complete.
   - Increment workload counter with runtime and final status labels.

3. **Registration**: Metrics registered with `prometheus.DefaultRegisterer` in an `init()` function or during backend construction.

4. **Consistency**: Follow the same patterns as existing metrics in `internal/api/metrics.go` (prometheus client_golang, default registerer, descriptive Help strings).

## Implementation Plan

1. Create `api/internal/backend/firecracker/metrics.go`.
2. Define and register all metric collectors.
3. Instrument `Execute` method with timing and counter updates.
4. Instrument `Cleanup` method with timing.
5. Verify metrics appear at `/metrics` endpoint.

## Test Plan

- **Registration**: Verify all metrics are registered without panics (no duplicate registration).
- **Instrumentation**: After a mock Execute call, verify histograms have observations and gauge reflects active count.
- **Labels**: Verify workload counter increments with correct runtime and status labels.
- **Cleanup metric**: Verify cleanup histogram records observation after Cleanup call.

## Verification

- `go vet ./...` — clean
- `go test -race -count=1 ./...` — all tests pass (6 new metrics tests + full suite)
- AI review round 1: 1 high (missing killed status), 2 medium (negative gauge, metric name). All fixed.
- AI review deferred: custom histogram buckets (low — matches existing patterns), test isolation (low — acceptable)

## Files Modified

- `api/internal/backend/firecracker/metrics.go` — created: 5 Prometheus metrics, init registration, pre-initialized counter labels
- `api/internal/backend/firecracker/metrics_test.go` — created: 6 tests for registration, labels, gauge, histograms
- `api/internal/backend/firecracker/backend.go` — modified: instrumentation in Execute and stopAndCleanup (boot timing, active VM gauge, vsock duration, cleanup timing, workload counter with completed/failed/killed)
